\section{Comparative Analysis of Existing Algorithms}
\label{sec:comparative-analysis}

\subsection{Mixture Models}
\begin{figure}[htbp]
\floatconts
  {fig:ahk2012-algo-a}
  {\caption{Algorithm A from AHK2012}}
  {\input{ahk2012-algo-a}}
\end{figure}

\begin{figure}[htbp]
\floatconts
  {fig:ahk2012-algo-b}
  {\caption{Algorithm B from AHK2012}}
  {\input{ahk2012-algo-b}}
\end{figure}

Let the absolute error of the inputs, $P_{12}$, $P_{13}$, $P_{123}$ be
$\aerr{P_{12}}, \aerr{P_{13}}$ and $\aerr{P_{123}}$ respectively. The
first step of the algorithm ``aligns'' $P_{123}$ with the singular
vectors of $P_{12}$.
\begin{align}
  \comment{\propositionref{prop:rot}} \aerr{\Up_1^T P_{12} \Up_2} &=& \aerr{P_{12}} \\
  \comment{\propositionref{prop:rot}} \aerr{\Up_1^T P_{123} \Up_2} &=& \aerr{P_{123}}.
\end{align}

Subsequently, $B_{123} = (\Up_1^T P_{123} \Up_2) \inv{(\Up_1^T P_{12} \Up_2)}$
is constructed,
\begin{align}
  \comment{\propositionref{prop:inv}} \aerr{\inv{P_{12}}} &=& \|\inv{P_{12}}\| \frac{ \cnd{A} }{\|P_{12}\| - \aerr{P_{12}} \cnd{A}} \aerr{P_{12}} \\
  \comment{\propositionref{prop:prod}} \aerr{B_{123}} &=& \aerr{P_{123}} \|\inv{P_{12}} \| + \|P_{123}\| \aerr{\inv{P_{12}}}.
\end{align}

$B_{123}$ is projected onto $k$ different $\theta_i$, and subsequently
diagonalised to give eigenvalues $\lambda_i$
\begin{align}
  \comment{\propositionref{prop:sim-eigd}} 
  \aerr{\lambda} &=& O(n^3) \cnd{R}^2 \|\inv{R}\| \inv{\gap{\lambda}}  \aerr{B_{123}} \\
  \comment{\propositionref{prop:proj}}
  \gap{\lambda} 
  &\le& \frac{\delta}{\sqrt{e} n^2 (1 + \sqrt{2\log(\frac{m}{\delta})})}
         \gap{\Up_3^T M_3} \\
  &\le& \frac{\delta}{\sqrt{e} n^2 (1 + \sqrt{2\log(\frac{m}{\delta})})}
         \gap{M_3}.
\end{align}

We can use the fact that $B_{123} = (\Up_1^T M_1) \diag( M_3^T \Up_3
\theta ) \inv{(\Up_1^T M_1)}$ to find $R$,
\begin{align}
  R &=& \Up_1^T M_1 \inv{\diag( \|\Up_1^T M_1 \vec{e}_1 \|, \cdots )} \\
  \| \inv{R} \| &\le& \cnd{\Up_1^T \|M_1\|} \\
          &\le& 2 \cnd{M_1} \\
  \cnd{R} &\le& 4 \cnd{M_1}^2.
\end{align}

Finally, in order to recover $M_3$ from $\lambda_i$, we need to invert
our projection, namely, $\mu_i = \Up_3^T \inv{\Theta} \lambda_i$. 
\begin{align}
  \aerr{\mu_i} &\le& \| \mu_i - \mup_i \|_2 \\
     &\le& \| \Up_3^T \inv{\Theta} \lambdap_i - \mu_i \|_2 \\
     &\le& \| \inv{\Theta} \lambdap_i - \Up_3 \mu_i \|_2 + \|\mu_i\|
     \frac{\|\inv{P_{13}}\| \aerr{P_{13}}}{1 - \|\inv{P_{13}}\| \aerr{P_{13}}} \\
     &\le& \| \inv{\Theta} (\lambdap_i - \lambda_i) \|_2 + 2 \|\mu_i\|
            \frac{\|\inv{P_{13}}\| \aerr{P_{13}}}{1 - \|\inv{P_{13}}\| \aerr{P_{13}}} \\
     &\le& \sqrt{k} \aerr{\lambda} + 2 \|\mu_i\|
            \frac{\|\inv{P_{13}}\| \aerr{P_{13}}}{1 - \|\inv{P_{13}}\| \aerr{P_{13}}} \\
\end{align}

\subsection{LDA}

\begin{figure}[htbp]
\floatconts
  {fig:2svd-lda}
  {\caption{Algorithm 5 from Two SVDs}}
  {\input{2svd-lda}}
\end{figure}

Let the absolute errors of the inputs, $\Pairs$ and $\Triples$ be $\aerr{P}$ and
$\aerr{T}$ respectively. The error in the whitening operator $W$ is then,
\begin{align}
  \comment{\propositionref{prop:white}} \aerr{W} &=& \frac{2}{\sigma_k(P)^2} (\beta_P) \\
  \|W\| &=& \frac{1}{\sqrt{\sigma_k(P)}} \\
  \|\Wp\| &\le& \frac{1}{\sqrt{\sigma_k(P) - \aerr{P}}} \\
          &=& \frac{\|W\|}{\sqrt{1 - \alpha_P}}.
\end{align}

The whitened tensor $T_W = \Triples[W,W,W]$ have the error, 
\begin{eqnarray}
  \aerr{T_W} 
    &\le& \|\Wp\| \aerr{T} + \|T\| (\|W\|^2 + \|W\|\|\Wp\| + \|\Wp\|^2 ) \\
    &\le& \frac{\|\inv{P}\|^{\half}}{\sqrt{1 - \alpha_P}} \aerr{T} + \|T\| \|\inv{P}\| (1 + \frac{1}{\sqrt{1 - \alpha_P}} + \frac{1}{1 - \alpha_P}).
\end{eqnarray}

The singular vectors of $T_W(\theta)$ have the error,
\begin{eqnarray}
  \aerr{v_i} 
    &\le& \frac{2 \sqrt{k} \aerr{T_W}}{\gap{T_W} - \aerr{T_W}}.
\end{eqnarray}

To make the calculation tractable, we assume $\aerr{T_W}
< \frac{\gap{T_W}}{2}$. By the random projection result, with probability $1-\delta$,  

\begin{eqnarray}
  \aerr{v_i} 
    &\le& \frac{2 \sqrt{k}}{\gap{T_W} - \aerr{T_W}}  \aerr{T_W}\\
    &\le& \frac{4 \sqrt{k}}{\gap{T_W}}  \aerr{T_W}\\
    &\approx& \frac{4 \sqrt{k} \aerr{T_W}}{\frac{\delta}{\sqrt{e} \binom{n}{2} (1 + \sqrt{2\log(\frac{k}{\delta})}) \gap{T}}} \\
    &=& \frac{4 \sqrt{ke} \binom{n}{2} (1 + \sqrt{2\log(\frac{k}{\delta})})}{\delta} \gap{T} \aerr{T_W}
\end{eqnarray}

\todo{$\gap{T_W}$ is not the same as the $\gap{A}$ use in AHK2012; needs some new notation.}

Finally, we must normalise these singular vectors, which we do by
projecting $v_i$ onto $W$, i.e. $(\pinv{W})^T v_i$ and dividing by $Z_i
= \frac{2}{(\alpha_0 + 2) T_W[v_i, v_i, v_i]}$ Thus, 

\begin{eqnarray}
  \aerr{O_i} 
  &\le& \| O_i - \Pi_W O_i \| + \| \Pi_W O_i - \frac{1}{\Zp_i} (\pinv{W})^T \vp_i \| \\
  &\le& \|\Pi - \Pi_W\| 
  + \frac{\|\pinv{W}\|}{Z_i} \aerr{v_i} 
  + \frac{\|\vp_i\|}{Z_i} \aerr{\pinv{W}} 
  + \|\pinv{\Wp}\| \|\vp_i\| \aerr{\frac{1}{Z_i}}.
\end{eqnarray}

\subsection{Spherical Gaussians}

