\section{Factorial models} \label{sec:factorialModels}

So far, we have relied on the existence of bottleneck hidden variables $h_j$ on which
we have three conditionally independent views.  Such bottlenecks do not always
exist; for example, in \reffig{factorialModels}(a), neither $h_1$ or $h_2$ is a bottleneck.
Our solution is to create a composite latent variable out of existing latent
variables.  We can invoke $\TensorFactorize$ to obtain composite marginals and
conditional means.  However, the identity of $h_1$ and $h_2$ becomes lost in the composite,
and must be recovered.  To do this, we develop a new algorithm $\UnshuffleFactorize$
to produce constraints on the original parameters.

\Fig{figures/factorialModels}{0.3}{factorialModels}{Examples of factorial models.
There do not exist three-view bottlenecks, so we first identify composite bottlenecks,
and then perform an \emph{unshuffling factorization}.}

%restricted Boltzmann machines \cite{salakhutdinov09softmax}

We focus on the factorial mixture model.
Let $h = (h_1, \dots, h_s) \in [\nh]^s$ be the latent variables (sources)
and $x = (x_1, x_2, x_3) \in [\nphix]^3$ be the observed variables.
\begin{align}
p_\theta(x, h) = \prod_{i=1}^s p_\theta(h_i) \prod_{j=1}^3 p_\theta(x_j \mid h), \quad
p_\theta(x_j \mid h) = \exp\left\{ \sum_{i=1}^s \theta_i(x_j, h_i) - A(\theta; h) \right\},
\end{align}
where each $\theta_i \in \R^{\nphix \times \nh}$ are the parameters for the $i$-th source.
%Let $\theta = (\theta_1, \dots, \theta_b) \in \R^{\nphix \times b \nh}$.

Let $B \eqdef (p_\theta(x_j \mid h))_{x_j \in [\nphix],h \in [\nh]^s} \in
\R^{\nphix \times \nh^s}$ be the conditional mean.

\begin{assumption}
  Assume that $B$ has full column rank ($k^s$).\footnote{Note that this implies
  $d \ge k^s$, which is a rather stringent assumption, but is necessary for the
  three-view method of moments technique to work.}
\end{assumption}

We will measure $M_2 \eqdef \E[x_1 \otimes x_2]$ and
$M_3 \eqdef \E[x_1 \otimes x_2 \otimes x_3]$.
We run $\TensorFactorize$, which will produce $B = (\E[x_j \mid c])$, where the
cluster $c$ ranges over $k^s$ possible clusters.  Next, we still have to
extract the actual parameters $\theta$ from $B$.  In the simple mixture model,
the clusters produced by $\TensorFactorize$ were in exact one-to-one correspondence
with the actual mixture components, but in the factorial case, we must solve
the \emph{credit assignment problem} to the $s$ sources.

Let $C$ be the elementwise logarithm of $B$; that is
$C(x_j, h) = \log B(x_j, h)$.

Let $v_{ia} = \theta_i(\cdot, a) \in \R^\ell$ be the collection of parameter vectors that we seek to recover.
What we observe are normalized sums of these vectors.
Specifically, we observe the unordered collection of vectors $\{ \sum_{i=1}^s v_{ia_i} - Z_{\ba} : \ba = (a_1, \dots, a_s) \in [\nh]^s \}$,
where $Z_{\ba} = \log \sum_{e=1}^\ell (\sum_{i=1}^s \exp(v_{ia_i}(e)))$ is the normalization constant.

We say two vectors are \emph{comparable} if they differ by a constant times $\bone$.

Here's the algorithm:
\begin{itemize}
  \item For each pair of vectors $(i,j) \in [\nh^s]^2$, consider the difference $B_i - B_j$.
  \item Put the pairs into bins, where each bin has differences which are comparable.
  \item Keep only the bins with the maximum number of pairs (which should be $\nh$).
  Now, each bin $b$ corresponds to a signature $v_{ia} - v_{ia'}$ for some source $i$ and two values $a$ and $a'$.
  \item Group the bins into sources.
  Construct a graph with the bins as nodes as follows.
  Let two bins be connected if the difference of their signatures is the signature of some other bin.
  For example, bin $b_1$ with signature $v_{ia} - v_{ia'}$
  is connected to bin $b_2$ with signature $v_{ia''} - v_{ia'}$
  because some bin $b_3$ has signature $v_{ia} - v_{ia''}$ by construction of the bins.
  The connected components of graph are exactly the sources.
  \item For each connected component, identify a subset of the signatures which all have a common difference:
  $v_{ia_1} - v_{ia'}$, $v_{ia_2} - v_{ia'}$, $v_{ia_3} - v_{ia'}$, etc.
  \item Construct a linear program.  It will have $\nh^s \cdot d$ constraints, one for each entry of $B$.
  It will have $s\nh \cdot d + \nh^s$ variables,
  one for each of $s\nh$ vectors $v_{ia}$ and $\nh^s$ for the normalization constant
  (these are actually deterministic functions of the vectors, but non-linear, so let's linearize).
  TODO: finish explaining this.
\end{itemize}
