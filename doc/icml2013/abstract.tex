\begin{abstract}

Discriminative latent-variable models are typically learned using
EM or gradient-based optimization, which suffer from local optima.
In this paper, we develop a new computationally efficient
and provably consistent estimator for a mixture of linear regressions,
a simple instance of a discriminative latent-variable model.
Our approach relies on a low-rank linear regression to recover
a symmetric tensor, which can be factorized into the parameters
using a tensor power method.
We prove rates of convergence for our estimator
and provide an empirical evaluation illustrating
its strengths relative to local optimization (EM).

%  Spectral algorithms for latent variable models have seen considerable
%  recent interest for being efficient consistent estimators of model
%  parameters. These algorithms make few if any assumptions about the
%  generative process of the data, while providing a polynomial sample
%  and computational complexity. We present a new spectral algorithm for
%  a discriminative model, a mixture of linear regressions and show that
%  it can recover the regression coefficients with similar polynomial
%  guarantees. We evaluate the algorithm on linearly and non-linearly
%  generated data, as well as on a motion tracking task and compare it's
%  characteristics with an E-M algorithm.
\textbf{Last Modified: \today}
\end{abstract} 
